{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline \n",
    "\n",
    "## 1.1 Carga de Información\n",
    "\n",
    "Ya que hemos configurado el manejador de base de datos ahora crearemos la DB, llamemosla `Transacciones`, como requerimos de las claves del service account para realizar la conexión no tenemos un gran riesgo de seguridad al dejar explícita la contraseña y el usser.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 # conector a PostgreSQL\n",
    "import pandas as pd # manioulacion de data.frames\n",
    "import numpy as np # operaciones vectorcizadas en C :D \n",
    "import gc # grabage collector para liberar memoria explicitamente "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisemos cómo vienen los datos crudos en el .csv, observando los primeros y últimos 50 registros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wc -l data_prueba_tecnica.csv # para conocer el numero de lineas del dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cargos_head = pd.read_csv('data_prueba_tecnica.csv', nrows=50, error_bad_lines=True, warn_bad_lines =True, skip_blank_lines=False)\n",
    "cargos_tail = pd.read_csv('data_prueba_tecnica.csv', nrows=50, skiprows=9950, header=None, \\\n",
    "                           names=list(cargos_head.columns), error_bad_lines=True, warn_bad_lines =True, skip_blank_lines=False)\n",
    "cargos = cargos_head.append( cargos_tail)#, ignore_index=True)\n",
    "cargos.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como ya no requerimos estos dataframes los eliminamos para liberar memoria \n",
    "del cargos_head\n",
    "del cargos_tail\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general los primeros y últimos registros lucen bien con excepción de de las líneas en blanco alternadas con cada registro con información, veamos cómo viene el dataset completo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cargos_row = pd.read_csv('data_prueba_tecnica.csv', error_bad_lines=True, warn_bad_lines =True, skip_blank_lines=True, \\\n",
    "                        encoding = 'utf-8', verbose =True, infer_datetime_format=True,  parse_dates= ['created_at', 'paid_at'])\n",
    "print(cargos_row.shape)\n",
    "cargos_row.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para sorpresa, no hay errores ni warnings en la lectura de los datos crudos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cargos_row.describe(include='all'))\n",
    "print('-------------------')\n",
    "print(cargos_row.shape)\n",
    "print(cargos_row.isna().sum()) #number of on.nas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De lo anterior es importante notar los siguientes puntos:\n",
    "- Existen 3 registros con `id` y `name` nulos, al igual que 4 `company_id`.\n",
    "- El campo `id` parece ser de buena calidad después de arreglar el punto anterior.\n",
    "- Existen 4 valores para el nombre de compañías diferentes que habrá que validar.\n",
    "- También en la limpieza tendremos que considerar la distribución de los valores para la columna `amount` y detectar valores atípicos. \n",
    "\n",
    "Finalmente validaremos que la fecha de actualización de los registros sea posterior a la fecha de creación del registro. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de nulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a seleccionar los registros con nulos para limpiarlos\n",
    "def Selec_na_index( data ): \n",
    "    '''\n",
    "    Inputs \n",
    "     data (pandas data.frame): Solo con las columnas de interes\n",
    "    Outputs:\n",
    "     index (numpy array):  Indices de data donde existen nulos \n",
    "    '''\n",
    "    columnas = data.columns\n",
    "    index =  [ list( data[x].index[ pd.isna( data[x] ) ])  for x in columnas ]\n",
    "    index = sum( index, []) \n",
    "    index.sort()\n",
    "    return( np.array(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como los registros con `id` nulo contienen información les asignamos uno para no perder esa información __posteriormente revisaremos el porqué estos registros ‘llegarón’ con  `id` nulo__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = Selec_na_index( cargos_row[['id', 'name', 'company_id', 'amount', 'status', 'created_at']])\n",
    "nulos = cargos_row.iloc[index]\n",
    "index = cargos_row['id'].index[ pd.isna( cargos_row['id'])]\n",
    "cargos_row['id'][index] = range(0, len(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para limpiar las columnas `name` y `company_id` nos valdremos de la misma información contenida en el dataset, construiremos un catálogo y sustituiremos los  nulos y valores atípicos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogo = cargos_row[['name', 'company_id']].drop_duplicates()\n",
    "catalogo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El catálogo nos permite ver que estamos en una situación sencilla todos los valores nulos y  anormales para `name` y `company_id` son asociados al valor `MiPasajefy`. Por lo que será sencillo limpiarlos, __sin embargo valdría la pena investigar el pipeline que produce este archivo ya que es curioso que solo se esté presentando para esta compañía__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = cargos_row['name'].index[ pd.isna( cargos_row['name'])]\n",
    "cargos_row['name'][index] = catalogo.name[0]\n",
    "index = cargos_row['company_id'].index[ pd.isna( cargos_row['company_id'])]\n",
    "cargos_row['company_id'][index] = catalogo.company_id[0]\n",
    "cargos_row = cargos_row.replace({'name':  {x : catalogo.name[0] for x in list(set(cargos_row.name)) if x not in ['Muebles chidos', 'MiPasajefy'] } } )\n",
    "cargos_row = cargos_row.replace({'company_id': { x : catalogo.company_id[0] for x in list(set(cargos_row.company_id))  if x not in ['8f642dc67fccf861548dfe1c761ce22f795e91f0', 'cbf1c8b09cd5b549416d49d220a40cbd317f952e'] } } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errores de encoding y validación de fechas \n",
    "\n",
    "Notamos que la columna`status` tiene errores de encoding, uno que puede identificarse a simple vista y otro que sustituiremos por un valor ‘Desconocido’, para no perder esta transacción y nuevamente __valdría la pena investigar el proceso que extrae este archivo porque este valor de encoding se presenta en la misma compañía en la que hemos tenido problemas__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(cargos_row.status))\n",
    "cargos_row = cargos_row = cargos_row.replace({'status':  { 'p&0x3fid' : 'paid',  '0xFFFF': 'desconocido'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(set(cargos_row.status))\n",
    "for i in a: \n",
    "    print(i)\n",
    "    print(i.encode().decode())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'a'.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
